name: transformer
d_model: 256
ff_mul: 2
num_heads: 4
num_layers_enc: 2
num_layers_dec: 2
label_pe_enc: false
label_pe_dec: false
deterministic: true
n_multi: null
temperature: 1
max_range_pe: 5000
diag_mask_width_below: ${.diag_mask_width_above}
diag_mask_width_above: null
average_attn_weights: true
store_attn_weights: false
mha_init_gain: 1
num_recurrent_steps: 1
multi_fwd_threshold: -1
dropout: 0.1
ckpt: null